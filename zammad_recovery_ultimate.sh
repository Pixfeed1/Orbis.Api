#!/bin/bash
################################################################################
# SCRIPT DE R√âCUP√âRATION POSTGRESQL/ZAMMAD - VERSION ULTIMATE
# Optimis√© pour: Image ext4 158GB, suppression 10/11/2025, clone 12/11/2025
# Cible: Backups PostgreSQL (.sql, .psql, .psql.gz) + Volumes Docker Zammad
################################################################################

set -e

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration par d√©faut
IMAGE_PATH="${1:-/mnt/d/rescue/vps-sda1.img}"
OUTPUT_DIR="${2:-/mnt/d/recovery_output}"
LOOP_DEVICE="${3:-/dev/loop0}"

echo -e "${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
echo -e "${GREEN}   üîç R√âCUP√âRATION POSTGRESQL/ZAMMAD - ULTIMATE EDITION${NC}"
echo -e "${BLUE}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
echo ""
echo -e "${YELLOW}Configuration:${NC}"
echo "  ‚Ä¢ Image     : $IMAGE_PATH"
echo "  ‚Ä¢ Device    : $LOOP_DEVICE"
echo "  ‚Ä¢ Sortie    : $OUTPUT_DIR"
echo "  ‚Ä¢ Date exec : $(date '+%Y-%m-%d %H:%M:%S')"
echo ""

# V√©rifications pr√©liminaires
if [ ! -e "$LOOP_DEVICE" ]; then
    echo -e "${RED}‚ùå ERREUR: Device $LOOP_DEVICE introuvable${NC}"
    echo "Montez d'abord l'image avec: sudo losetup -fP $IMAGE_PATH"
    exit 1
fi

if [ "$EUID" -ne 0 ]; then
    echo -e "${RED}‚ùå ERREUR: Ce script doit √™tre ex√©cut√© avec sudo${NC}"
    exit 1
fi

# Cr√©ation de la structure de sortie
mkdir -p "$OUTPUT_DIR"/{1_debugfs,2_scalpel,3_binwalk,4_strings,5_manual,6_docker,reports}

# Fonction de log
log() {
    echo -e "${GREEN}[$(date '+%H:%M:%S')]${NC} $1"
    echo "[$(date '+%H:%M:%S')] $1" >> "$OUTPUT_DIR/reports/recovery.log"
}

# Fonction de statistiques
stats() {
    local dir=$1
    local count=$(find "$dir" -type f 2>/dev/null | wc -l)
    local size=$(du -sh "$dir" 2>/dev/null | cut -f1)
    echo "    ‚Üí $count fichiers ($size)"
}

################################################################################
# √âTAPE 1: DEBUGFS - R√âCUP√âRATION D'INODES SUPPRIM√âS
################################################################################
log "‚ïê‚ïê‚ïê [1/7] ANALYSE DEBUGFS - Inodes supprim√©s ‚ïê‚ïê‚ïê"

debugfs -R "lsdel" "$LOOP_DEVICE" 2>/dev/null > "$OUTPUT_DIR/1_debugfs/deleted_inodes.txt" || {
    log "‚ö†Ô∏è  debugfs lsdel a √©chou√©, on continue..."
}

# Analyser et trier les inodes par taille
if [ -f "$OUTPUT_DIR/1_debugfs/deleted_inodes.txt" ]; then
    log "Filtrage des gros fichiers (>500KB, probablement des backups)..."

    # Fichiers >500KB
    awk '$6 > 1024 {printf "Inode: %s | Taille: %.2f MB | Supprim√©: %s %s\n", $1, $6*512/1024/1024, $8, $9}' \
        "$OUTPUT_DIR/1_debugfs/deleted_inodes.txt" | tee "$OUTPUT_DIR/1_debugfs/large_files.txt"

    # Restaurer automatiquement les 50 plus gros fichiers
    log "Restauration des 50 plus gros fichiers supprim√©s..."
    awk '$6 > 1024 {print $1}' "$OUTPUT_DIR/1_debugfs/deleted_inodes.txt" | head -50 | while read inode; do
        if [ -n "$inode" ]; then
            debugfs -R "dump <$inode> $OUTPUT_DIR/1_debugfs/recovered_inode_$inode" "$LOOP_DEVICE" 2>/dev/null || true
        fi
    done

    stats "$OUTPUT_DIR/1_debugfs"
fi

################################################################################
# √âTAPE 2: SCALPEL - CARVING PAR SIGNATURES
################################################################################
log "‚ïê‚ïê‚ïê [2/7] SCALPEL - Recherche par signatures ‚ïê‚ïê‚ïê"

# Cr√©er configuration scalpel ultra-sp√©cialis√©e
cat > "$OUTPUT_DIR/2_scalpel/scalpel.conf" << 'SCALPEL_EOF'
# Configuration optimis√©e pour PostgreSQL/Zammad

# Dumps PostgreSQL (signatures multiples)
sql     y   500000000   --\n--\ PostgreSQL\ database\ dump
sql     y   500000000   PGDMP
sql     y   500000000   pg_dump\ version
sql     y   500000000   --\ Dumped\ from\ database\ version
sql     y   500000000   --\ Dumped\ by\ pg_dump
sql     y   500000000   CREATE\ DATABASE\ zammad
sql     y   500000000   \\connect\ zammad

# Archives compress√©es
gz      y   500000000   \x1f\x8b\x08
bz2     y   500000000   BZh
xz      y   500000000   \xfd\x37\x7a\x58\x5a\x00

# Tar archives (volumes Docker)
tar     y   500000000   ustar\x00
tar     y   500000000   ustar\x20\x20\x00

# Fichiers .psql sp√©cifiques
psql    y   500000000   SET\ statement_timeout
psql    y   500000000   SET\ client_encoding
SCALPEL_EOF

log "Lancement de scalpel (peut prendre 30-60 min)..."
scalpel -c "$OUTPUT_DIR/2_scalpel/scalpel.conf" -o "$OUTPUT_DIR/2_scalpel/output" "$LOOP_DEVICE" 2>&1 | \
    tee "$OUTPUT_DIR/2_scalpel/scalpel.log"

stats "$OUTPUT_DIR/2_scalpel/output"

################################################################################
# √âTAPE 3: BINWALK - EXTRACTION D'ARCHIVES ENFOUIES
################################################################################
log "‚ïê‚ïê‚ïê [3/7] BINWALK - Extraction archives ‚ïê‚ïê‚ïê"

log "Recherche des archives gzip/tar enfouies..."
binwalk -e -C "$OUTPUT_DIR/3_binwalk" --run-as=root "$LOOP_DEVICE" 2>&1 | \
    tee "$OUTPUT_DIR/3_binwalk/binwalk.log" || {
    log "‚ö†Ô∏è  binwalk partiel, on continue..."
}

stats "$OUTPUT_DIR/3_binwalk"

################################################################################
# √âTAPE 4: STRINGS - ANALYSE DES CHA√éNES
################################################################################
log "‚ïê‚ïê‚ïê [4/7] STRINGS - Recherche de patterns ‚ïê‚ïê‚ïê"

log "Recherche des signatures PostgreSQL..."
strings -a -t d "$LOOP_DEVICE" | grep -iE "pg_dump|postgresql.*dump|pgdmp|zammad_production" | \
    head -1000 > "$OUTPUT_DIR/4_strings/postgresql_offsets.txt" 2>&1 || true

log "Recherche des noms de fichiers .sql/.psql..."
strings -a -t d "$LOOP_DEVICE" | grep -E "\.sql$|\.psql|\.sql\.gz$|backup.*sql|dump.*sql" | \
    head -500 > "$OUTPUT_DIR/4_strings/sql_filenames.txt" 2>&1 || true

log "Recherche de 'zammad' dans le disque..."
strings -a -t d "$LOOP_DEVICE" | grep -i "zammad" | head -1000 > "$OUTPUT_DIR/4_strings/zammad_refs.txt" 2>&1 || true

log "Recherche des chemins Docker volumes..."
strings -a -t d "$LOOP_DEVICE" | grep "var/lib/docker/volumes" | \
    head -200 > "$OUTPUT_DIR/4_strings/docker_paths.txt" 2>&1 || true

echo "  R√©sultats:"
[ -f "$OUTPUT_DIR/4_strings/postgresql_offsets.txt" ] && \
    echo "    ‚Üí PostgreSQL offsets: $(wc -l < "$OUTPUT_DIR/4_strings/postgresql_offsets.txt")"
[ -f "$OUTPUT_DIR/4_strings/sql_filenames.txt" ] && \
    echo "    ‚Üí SQL filenames: $(wc -l < "$OUTPUT_DIR/4_strings/sql_filenames.txt")"
[ -f "$OUTPUT_DIR/4_strings/zammad_refs.txt" ] && \
    echo "    ‚Üí Zammad refs: $(wc -l < "$OUTPUT_DIR/4_strings/zammad_refs.txt")"

################################################################################
# √âTAPE 5: EXTRACTION MANUELLE DES MEILLEURS CANDIDATS
################################################################################
log "‚ïê‚ïê‚ïê [5/7] EXTRACTION MANUELLE - Top candidats ‚ïê‚ïê‚ïê"

if [ -f "$OUTPUT_DIR/4_strings/postgresql_offsets.txt" ]; then
    log "Extraction des 20 meilleurs offsets PostgreSQL..."

    head -20 "$OUTPUT_DIR/4_strings/postgresql_offsets.txt" | while IFS= read -r line; do
        offset=$(echo "$line" | awk '{print $1}')

        if [ -n "$offset" ] && [ "$offset" -gt 0 ] 2>/dev/null; then
            log "  ‚Üí Extraction √† offset $offset..."

            # Extraire 100MB √† partir de l'offset
            dd if="$LOOP_DEVICE" of="$OUTPUT_DIR/5_manual/fragment_offset_$offset.raw" \
               bs=1 skip="$offset" count=104857600 2>/dev/null || true
        fi
    done
fi

# Recherche binaire directe de signatures PGDMP
log "Recherche binaire des signatures PGDMP..."
grep -abo "PGDMP" "$LOOP_DEVICE" 2>/dev/null | head -10 | while IFS=: read offset match; do
    log "  ‚Üí PGDMP trouv√© √† offset $offset"
    dd if="$LOOP_DEVICE" of="$OUTPUT_DIR/5_manual/pgdmp_$offset.raw" \
       bs=1 skip="$offset" count=52428800 2>/dev/null || true
done

stats "$OUTPUT_DIR/5_manual"

################################################################################
# √âTAPE 6: FOCUS DOCKER VOLUMES
################################################################################
log "‚ïê‚ïê‚ïê [6/7] DOCKER VOLUMES - Recherche sp√©cifique ‚ïê‚ïê‚ïê"

# Chercher les m√©tadonn√©es de volumes Zammad
log "Recherche volumes zammad-docker-compose..."
strings -a "$LOOP_DEVICE" | grep -i "zammad-docker-compose" | head -100 > \
    "$OUTPUT_DIR/6_docker/zammad_volumes.txt" 2>&1 || true

# Recherche des fichiers de backup Zammad typiques
log "Recherche patterns de backup Zammad..."
strings -a -t d "$LOOP_DEVICE" | grep -iE "zammad.*backup|backup.*zammad|zammad.*\.sql" | head -200 > \
    "$OUTPUT_DIR/6_docker/zammad_backup_patterns.txt" 2>&1 || true

stats "$OUTPUT_DIR/6_docker"

################################################################################
# √âTAPE 7: D√âCOMPRESSION ET VALIDATION
################################################################################
log "‚ïê‚ïê‚ïê [7/7] D√âCOMPRESSION - Fichiers .gz trouv√©s ‚ïê‚ïê‚ïê"

log "Recherche et d√©compression des archives .gz..."
find "$OUTPUT_DIR" -name "*.gz" -type f 2>/dev/null | while read gzfile; do
    base=$(basename "$gzfile" .gz)
    dir=$(dirname "$gzfile")

    log "  ‚Üí D√©compression: $base"
    gunzip -c "$gzfile" > "$dir/decompressed_$base.sql" 2>/dev/null || true

    # Test si c'est du SQL valide
    if head -5 "$dir/decompressed_$base.sql" 2>/dev/null | grep -qi "postgresql\|create\|insert"; then
        log "    ‚úÖ SQL VALIDE TROUV√â!"
        cp "$dir/decompressed_$base.sql" "$OUTPUT_DIR/reports/VALID_SQL_$base.sql"
    fi
done

################################################################################
# RAPPORT FINAL
################################################################################
log "‚ïê‚ïê‚ïê G√âN√âRATION DU RAPPORT FINAL ‚ïê‚ïê‚ïê"

cat > "$OUTPUT_DIR/reports/RAPPORT_FINAL.txt" << REPORT_EOF
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  RAPPORT DE R√âCUP√âRATION POSTGRESQL/ZAMMAD
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Date d'ex√©cution: $(date '+%Y-%m-%d %H:%M:%S')
Image analys√©e: $IMAGE_PATH
Device: $LOOP_DEVICE

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  üìä STATISTIQUES DE R√âCUP√âRATION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. DEBUGFS (Inodes supprim√©s):
$(stats "$OUTPUT_DIR/1_debugfs")

2. SCALPEL (Signatures):
$(stats "$OUTPUT_DIR/2_scalpel")

3. BINWALK (Archives):
$(stats "$OUTPUT_DIR/3_binwalk")

4. STRINGS (Offsets):
   ‚Ä¢ PostgreSQL refs: $(wc -l < "$OUTPUT_DIR/4_strings/postgresql_offsets.txt" 2>/dev/null || echo "0")
   ‚Ä¢ SQL filenames: $(wc -l < "$OUTPUT_DIR/4_strings/sql_filenames.txt" 2>/dev/null || echo "0")
   ‚Ä¢ Zammad refs: $(wc -l < "$OUTPUT_DIR/4_strings/zammad_refs.txt" 2>/dev/null || echo "0")

5. EXTRACTION MANUELLE:
$(stats "$OUTPUT_DIR/5_manual")

6. DOCKER VOLUMES:
$(stats "$OUTPUT_DIR/6_docker")

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  üéØ FICHIERS √Ä V√âRIFIER EN PRIORIT√â
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. Fichiers SQL valides trouv√©s:
$(find "$OUTPUT_DIR/reports" -name "VALID_SQL_*.sql" -type f -ls 2>/dev/null || echo "   Aucun")

2. Plus gros fichiers r√©cup√©r√©s par debugfs:
$(find "$OUTPUT_DIR/1_debugfs" -name "recovered_inode_*" -type f -exec ls -lh {} \; 2>/dev/null | sort -k5 -hr | head -10 || echo "   Aucun")

3. Fichiers SQL trouv√©s par scalpel:
$(find "$OUTPUT_DIR/2_scalpel" -name "*.sql" -type f -ls 2>/dev/null | head -10 || echo "   Aucun")

4. Fragments manuels les plus gros:
$(find "$OUTPUT_DIR/5_manual" -type f -exec ls -lh {} \; 2>/dev/null | sort -k5 -hr | head -5 || echo "   Aucun")

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  üîç PROCHAINES √âTAPES RECOMMAND√âES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

1. V√©rifiez les fichiers marqu√©s VALID_SQL_* dans reports/

2. Testez les plus gros fichiers debugfs:
   cd $OUTPUT_DIR/1_debugfs
   for f in recovered_inode_*; do
       file \$f
       head -20 \$f
   done

3. Examinez les fichiers scalpel:
   find $OUTPUT_DIR/2_scalpel -name "*.sql" -exec head -20 {} \;

4. V√©rifiez les fragments manuels:
   cd $OUTPUT_DIR/5_manual
   for f in *.raw; do
       strings \$f | head -50
   done

5. Testez la restauration PostgreSQL:
   psql -U postgres -d test_db -f fichier_recupere.sql

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
  üí° ANALYSE DES CHANCES DE R√âCUP√âRATION
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

Facteurs POSITIFS ‚úÖ:
‚Ä¢ Clone fait seulement 2 jours apr√®s suppression
‚Ä¢ Image ext4 bien pr√©serv√©e
‚Ä¢ Multiples techniques de r√©cup√©ration utilis√©es

Facteurs N√âGATIFS ‚ùå:
‚Ä¢ R√©installation Zammad le soir m√™me (√©crasement partiel)
‚Ä¢ D√©lai de 2 jours = risque de r√©utilisation des blocs

Estimation globale: 30-50% de r√©cup√©ration partielle possible

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
REPORT_EOF

echo ""
echo -e "${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
echo -e "${GREEN}  ‚úÖ R√âCUP√âRATION TERMIN√âE !${NC}"
echo -e "${GREEN}‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê${NC}"
echo ""
echo -e "${YELLOW}üìÇ R√©sultats sauvegard√©s dans:${NC} $OUTPUT_DIR"
echo ""
echo -e "${BLUE}üìã Consultez le rapport complet:${NC}"
echo "   cat $OUTPUT_DIR/reports/RAPPORT_FINAL.txt"
echo ""
echo -e "${BLUE}üîç V√©rifiez en priorit√©:${NC}"
echo "   1. $OUTPUT_DIR/reports/VALID_SQL_*.sql"
echo "   2. $OUTPUT_DIR/1_debugfs/recovered_inode_*"
echo "   3. $OUTPUT_DIR/2_scalpel/output/"
echo ""

# Afficher un aper√ßu des fichiers trouv√©s
if compgen -G "$OUTPUT_DIR/reports/VALID_SQL_*.sql" > /dev/null; then
    echo -e "${GREEN}üéâ FICHIERS SQL VALIDES TROUV√âS !${NC}"
    ls -lh "$OUTPUT_DIR/reports/VALID_SQL_"*.sql
    echo ""
fi

# Statistiques finales
total_files=$(find "$OUTPUT_DIR" -type f 2>/dev/null | wc -l)
total_size=$(du -sh "$OUTPUT_DIR" 2>/dev/null | cut -f1)

echo -e "${YELLOW}üìä Total r√©cup√©r√©:${NC} $total_files fichiers ($total_size)"
echo ""
echo -e "${BLUE}Log complet:${NC} $OUTPUT_DIR/reports/recovery.log"
echo ""

log "‚ïê‚ïê‚ïê Script termin√© avec succ√®s ‚ïê‚ïê‚ïê"

exit 0
